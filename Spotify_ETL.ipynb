{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82adba96-0961-46cf-a319-99ceaf2999b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Extracting Data from Spotify_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5896fa32-8d73-4075-987d-9d29e72e8eda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "playlist_id=dbutils.widgets.text(\"playlist_id\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d15ebd15-7caa-41ad-90f8-c774f2d8bfa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType , LongType , DoubleType  , BooleanType , TimestampType , IntegerType , DateType\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5477ab96-7104-4c71-9855-ff14ec0fbc9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-7123dcbc-cd4a-4877-aaa4-62/.ipykernel/18292/command-8133604339286368-3700390929:8: DeprecationWarning: You're using 'as_dict = True'.get_access_token will return the token string directly in future versions. Please adjust your code accordingly, or use get_cached_token instead.\n",
      "  token_info = sp.auth_manager.get_access_token(as_dict=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Access token retrieved successfully. Authentication is working.\n",
      "Token will expire in 3600 seconds.\n"
     ]
    }
   ],
   "source": [
    "client_id=dbutils.secrets.get(\"Spotify_auth_details\",\"client_id\")\n",
    "client_secret=dbutils.secrets.get(\"Spotify_auth_details\",\"client_secret\")\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id,\n",
    "                                                            client_secret=client_secret))\n",
    "\n",
    "try:\n",
    "    token_info = sp.auth_manager.get_access_token(as_dict=True)\n",
    "    if token_info and 'access_token' in token_info:\n",
    "        print(\"SUCCESS: Access token retrieved successfully. Authentication is working.\")\n",
    "        print(f\"Token will expire in {token_info.get('expires_in', 'N/A')} seconds.\")\n",
    "    else:\n",
    "        print(\"FAILURE: Access token could NOT be retrieved. This is the root of your 403 error.\")\n",
    "        print(\"Double-check your Client ID and Client Secret on the Spotify Developer Dashboard.\")\n",
    "except spotipy.SpotifyException as e:\n",
    "    print(f\"SPOTIPY EXCEPTION during authentication test: {e}\")\n",
    "    print(\"This indicates a problem with your credentials or permissions.\")\n",
    "except Exception as e:\n",
    "    print(f\"GENERIC EXCEPTION during authentication test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "155fc9a6-40b2-42b3-8c4b-9d9a7be37b65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00bf8321-7237-44d8-9066-caa619236cd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_all_playlist_items(spotipy_client: spotipy.Spotify, playlist_id: str) -> list:\n",
    "    all_items = []\n",
    "    offset = 0\n",
    "    limit = 100\n",
    "    while True:\n",
    "        response = spotipy_client.playlist_items(playlist_id, limit=limit, offset=offset)\n",
    "        if not response or not response.get('items'):\n",
    "            break\n",
    "        all_items.extend(response['items'])\n",
    "        if len(response['items']) < limit: \n",
    "            break\n",
    "        offset += limit\n",
    "    return all_items\n",
    "\n",
    "def get_batch_items(spotipy_client: spotipy.Spotify, func, item_ids: list, batch_size: int = 50) -> list:\n",
    "    \"\"\"Fetches items in batches from Spotify API using a given spotipy function.\"\"\"\n",
    "    all_results = []\n",
    "    if not item_ids:\n",
    "        return [] \n",
    "\n",
    "    for i in range(0, len(item_ids), batch_size):\n",
    "        batch = item_ids[i:i + batch_size] \n",
    "        try:\n",
    "            response = func(batch) # Make the API call with the batch of IDs\n",
    "            if response:\n",
    "                if func == spotipy_client.albums:\n",
    "                    if 'albums' in response and response['albums']:\n",
    "                        all_results.extend([item for item in response['albums'] if item is not None])\n",
    "                elif func == spotipy_client.tracks:\n",
    "                    if 'tracks' in response and response['tracks']:\n",
    "                        all_results.extend([item for item in response['tracks'] if item is not None])\n",
    "                elif func == spotipy_client.artists:\n",
    "                    if 'artists' in response and response['artists']:\n",
    "                        all_results.extend([item for item in response['artists'] if item is not None])\n",
    "                else:\n",
    "                    print(f\"Warning: Unexpected response structure for {func.__name__}\")\n",
    "        except spotipy.SpotifyException as e:\n",
    "            print(f\"Error during batch call for {func.__name__} with IDs {batch}: {e}\")\n",
    "    return all_results\n",
    "\n",
    "def process_playlists(playlist_id: str) -> F.DataFrame:\n",
    "    \n",
    "    try:        raw_playlist_items = get_all_playlist_items(sp, playlist_id)\n",
    "    except ConnectionError as e:\n",
    "        print(f\"Connection error occurred: {e}\")\n",
    "        raw_playlist_items = []\n",
    "\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"added_at\", StringType()), \n",
    "        StructField(\"track\", StructType([  \n",
    "            StructField(\"artists\", ArrayType(StructType([\n",
    "            StructField(\"id\", StringType()),\n",
    "            StructField(\"name\", StringType()),\n",
    "            ]))),\n",
    "            StructField(\"album\",StructType([\n",
    "                StructField(\"album_type\", StringType()),\n",
    "                StructField(\"id\", StringType()),\n",
    "                StructField(\"name\", StringType()),\n",
    "                StructField(\"release_date\", StringType()),\n",
    "                StructField(\"total_tracks\", LongType()),\n",
    "           \n",
    "                     \n",
    "            ])),\n",
    "            StructField(\"duration_ms\", LongType()),\n",
    "            StructField(\"id\", StringType()),\n",
    "            StructField(\"name\", StringType()),\n",
    "            StructField(\"popularity\", LongType()),\n",
    "            StructField(\"explicit\", BooleanType()), \n",
    "        ])), \n",
    "        StructField(\"added_by\", StructType([\n",
    "            StructField(\"id\", StringType()), \n",
    "            StructField(\"name\", StringType())\n",
    "        ]))\n",
    "        ])\n",
    "    \n",
    "    if not raw_playlist_items:\n",
    "        print(\"No items found for this playlist.\")\n",
    "        return spark.createDataFrame([],schema) \n",
    "\n",
    "    df = spark.createDataFrame(raw_playlist_items,schema)\n",
    "    print(\"Playlist DataFrame created. Inferred Schema:\")\n",
    "    df.printSchema()\n",
    "    return df\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "519e5647-fbc0-4a98-8229-068b44543240",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Transformation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02295979-7e98-40a0-946b-b66bbd0ca1dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "playlistid=dbutils.widgets.get(\"playlist_id\")\n",
    "\n",
    "def get_most_popular_genres(playlist_id: str):\n",
    "    \"\"\"\n",
    "    Retrieves the most popular genres from artists associated with tracks in a playlist.\n",
    "    \"\"\"\n",
    "    tracks_df = process_playlists(playlist_id)\n",
    "\n",
    "    if tracks_df.isEmpty():\n",
    "        return spark.createDataFrame([], StructType([StructField(\"genre\", StringType()), StructField(\"count\", StringType())]))\n",
    "\n",
    "    artists_details_df = get_artist_details_for_enrichment(tracks_df)\n",
    "    \n",
    "    artists_details_df.printSchema()\n",
    "    artists_details_df.show(5, truncate=False) \n",
    "\n",
    "    if artists_details_df.isEmpty():\n",
    "        print(\"No artist details found to extract genres from.\")\n",
    "        return spark.createDataFrame([], StructType([StructField(\"genre\", StringType()), StructField(\"count\", LongType())]))\n",
    "    artists_details_df.printSchema()\n",
    "\n",
    "   \n",
    "    # An artist can have multiple genres, so we explode the 'genres' array.\n",
    "    # Each genre becomes a new row for that artist.\n",
    "    genres_df = artists_details_df.select(F.explode(\"genres\").alias(\"genre\")) \\\n",
    "                                  .filter(F.col(\"genre\").isNotNull()) \\\n",
    "                                  .groupBy(\"genre\").count() \\\n",
    "                                  .orderBy(F.desc(\"count\")) \n",
    "\n",
    "    return genres_df\n",
    "\n",
    "def get_artist_details_for_enrichment(tracks_df: F.DataFrame):\n",
    "   \n",
    "    if tracks_df.isEmpty():\n",
    "        return spark.createDataFrame([], StructType([\n",
    "            StructField(\"artist_id\", StringType(), True),\n",
    "            StructField(\"ArtistGenres\", ArrayType(StringType()), True),\n",
    "            StructField(\"ArtistPopularity\", IntegerType(), True),\n",
    "            StructField(\"ArtistFollowers\", LongType(), True)\n",
    "        ]))\n",
    "\n",
    "    artist_ids_df = tracks_df.select(F.explode(\"track.artists\").alias(\"artist\")) \\\n",
    "                              .select(F.col(\"artist.id\").alias(\"artist_id\")) \\\n",
    "                              .filter(F.col(\"artist_id\").isNotNull()) \\\n",
    "                              .dropDuplicates()\n",
    "\n",
    "    artist_ids_list_row = artist_ids_df.select(F.collect_list(\"artist_id\")).first()\n",
    "    artist_ids_list = artist_ids_list_row[0] if artist_ids_list_row else []\n",
    "\n",
    "    if not artist_ids_list:\n",
    "        print(\"No artists found in the playlist to get genres from.\")\n",
    "        return spark.createDataFrame([], StructType([\n",
    "            StructField(\"artist_id\", StringType(), True),\n",
    "            StructField(\"ArtistGenres\", ArrayType(StringType()), True),\n",
    "            StructField(\"ArtistPopularity\", IntegerType(), True),\n",
    "            StructField(\"ArtistFollowers\", LongType(), True)\n",
    "        ]))\n",
    "\n",
    "    print(f\"Fetching details for {len(artist_ids_list)} unique artists...\")\n",
    "    raw_artist_details = get_batch_items(sp, sp.artists, artist_ids_list)\n",
    "\n",
    "    raw_artist_schema = StructType([\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"genres\", ArrayType(StringType()), True),\n",
    "        StructField(\"popularity\", IntegerType(), True),\n",
    "        StructField(\"followers\", StructType([StructField(\"total\", LongType(), True)]), True),\n",
    "    ])\n",
    "\n",
    "    artists_details_df = spark.createDataFrame([item for item in raw_artist_details if item is not None], schema=raw_artist_schema)\n",
    "\n",
    "    artists_for_join_df = artists_details_df.select(\n",
    "        F.col(\"id\").alias(\"artist_id\"),\n",
    "        F.col(\"genres\").alias(\"ArtistGenres\"),\n",
    "        F.col(\"popularity\").alias(\"ArtistPopularity\"),\n",
    "        F.col(\"followers.total\").alias(\"ArtistFollowers\")\n",
    "    ).filter(F.col(\"artist_id\").isNotNull())\n",
    "\n",
    "    return artists_for_join_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b389fdd7-5295-41d7-913c-bb6408098a2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_artists_name_ids(playlist_id: str):\n",
    "    \"\"\"\n",
    "    Retrieves distinct artist names and IDs from a playlist.\n",
    "    Simplifies the original posexplode logic for better readability and efficiency.\n",
    "    \"\"\"\n",
    "    tracks_df = process_playlists(playlist_id)\n",
    "\n",
    "    if tracks_df.isEmpty():\n",
    "        return spark.createDataFrame([], StructType([StructField(\"artist_id\", StringType(), True), StructField(\"artist_name\", StringType(), True)]))\n",
    "\n",
    "   \n",
    "    artists_df = tracks_df.select(F.explode(\"track.artists\").alias(\"artist\")) \\\n",
    "                          .select(\n",
    "                              F.col(\"artist.id\").alias(\"artist_id\"),\n",
    "                              F.col(\"artist.name\").alias(\"artist_name\")\n",
    "                          ) \\\n",
    "                          .filter(F.col(\"artist_id\").isNotNull()) \\\n",
    "                          .dropDuplicates([\"artist_id\", \"artist_name\"]) \n",
    "\n",
    "   \n",
    "    print(\"Artists Names and IDs DataFrame created. Inferred Schema:\")\n",
    "    artists_df.printSchema()\n",
    "    return artists_df\n",
    "\n",
    "def get_playlists(playlist_id: str):\n",
    "    \"\"\"\n",
    "    Retrieves detailed and flattened playlist track information, matching the original output structure.\n",
    "    \"\"\"\n",
    "    raw_tracks_df = process_playlists(playlist_id)\n",
    "    if raw_tracks_df.isEmpty():\n",
    "        empty_playlist_schema = StructType([\n",
    "            StructField(\"album_type\", StringType(), True),\n",
    "            StructField(\"album_id\", StringType(), True),\n",
    "            StructField(\"album_name\", StringType(), True),\n",
    "            StructField(\"release_date\", StringType(), True),\n",
    "            StructField(\"total_tracks\", LongType(), True),\n",
    "            StructField(\"artist_id\", StringType(), True), \n",
    "            StructField(\"artist_name\", StringType(), True),\n",
    "            StructField(\"duration_ms\", LongType(), True),\n",
    "            StructField(\"track_id\", StringType(), True),\n",
    "            StructField(\"track_name\", StringType(), True),\n",
    "            StructField(\"popularity\", LongType(), True),\n",
    "            StructField(\"track_number\", LongType(), True),\n",
    "            StructField(\"explicit\", BooleanType(), True),\n",
    "\n",
    "        ])\n",
    "        return spark.createDataFrame([], empty_playlist_schema)\n",
    "\n",
    "   \n",
    "    # F.explode(F.col(\"track.artists.name\")) is used to get one row per artist name per track.\n",
    "    playlists_df = raw_tracks_df.select(\n",
    "        F.col(\"track.album.album_type\").alias(\"album_type\"),\n",
    "        F.col(\"track.album.id\").alias(\"album_id\"),\n",
    "        F.col(\"track.album.name\").alias(\"album_name\"),\n",
    "        F.col(\"track.album.release_date\").alias(\"release_date\"),\n",
    "        F.col(\"track.album.total_tracks\").alias(\"total_tracks\"),\n",
    "        F.explode(F.col(\"track.artists\")).alias(\"exploded_artist\"),\n",
    "        F.col(\"track.duration_ms\").alias(\"duration_ms\"),\n",
    "        F.col(\"track.id\").alias(\"track_id\"),\n",
    "        F.col(\"track.name\").alias(\"track_name\"),\n",
    "        F.col(\"track.popularity\").alias(\"popularity\"),\n",
    "        F.col(\"track.explicit\").alias(\"explicit\")\n",
    "         ).select( # Select again after explode to get specific artist fields\n",
    "        F.col(\"album_type\"),\n",
    "        F.col(\"album_id\"),\n",
    "        F.col(\"album_name\"),\n",
    "        F.col(\"release_date\"),\n",
    "        F.col(\"total_tracks\"),\n",
    "        F.col(\"exploded_artist.name\").alias(\"artist_name\"),\n",
    "        F.col(\"exploded_artist.id\").alias(\"artist_id\"),     \n",
    "       F.col(\"duration_ms\"),\n",
    "        F.col(\"track_id\"),\n",
    "        F.col(\"track_name\"),\n",
    "        F.col(\"popularity\"),\n",
    "        F.col(\"explicit\")\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Flattened Playlist Tracks DataFrame created. Inferred Schema:\")\n",
    "    playlists_df.printSchema()\n",
    "    return playlists_df\n",
    "\n",
    "\n",
    "def get_albums(albums_ids: list):\n",
    "    \"\"\"\n",
    "    Retrieves album details for a list of album IDs and flattens them.\n",
    "    Uses batching for efficient API calls.\n",
    "    \"\"\"\n",
    "    if not albums_ids:\n",
    "        empty_album_track_schema = StructType([\n",
    "            StructField(\"album_name\", StringType(), True),\n",
    "            StructField(\"release_date\", StringType(), True),\n",
    "            StructField(\"type\", StringType(), True),\n",
    "            StructField(\"artist_name\", StringType(), True),\n",
    "            StructField(\"track_id\", StringType(), True),\n",
    "            StructField(\"duration_ms\", LongType(), True),\n",
    "            StructField(\"popularity\", LongType(), True),\n",
    "            StructField(\"track_number\", LongType(), True),\n",
    "\n",
    "        ])\n",
    "        return spark.createDataFrame([], empty_album_track_schema)\n",
    "\n",
    "    print(f\"Fetching details for {len(albums_ids)} unique albums...\")\n",
    "    raw_albums_data = get_batch_items(sp, sp.albums, albums_ids)\n",
    "\n",
    "    if not raw_albums_data:\n",
    "        print(\"No album details fetched.\")\n",
    "        return spark.createDataFrame([], empty_album_track_schema)\n",
    "\n",
    "    album_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"release_date\", StringType(), True),\n",
    "    StructField(\"album_type\", StringType(), True),\n",
    "    StructField(\"artists\", ArrayType(StructType([\n",
    "        StructField(\"name\", StringType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"tracks\", StructType([\n",
    "        StructField(\"items\", ArrayType(StructType([\n",
    "            StructField(\"id\", StringType(), True),\n",
    "            StructField(\"duration_ms\", LongType(), True),\n",
    "            StructField(\"track_number\", LongType(), True)\n",
    "\n",
    "        ])), True)\n",
    "    ]), True),\n",
    "    StructField(\"popularity\", LongType(), True),\n",
    "    StructField(\"explicit\", BooleanType(), True), \n",
    "\n",
    "])\n",
    "\n",
    "    albums_df = spark.createDataFrame(raw_albums_data,album_schema)\n",
    "    print(\"Albums Details DataFrame created. Inferred Schema:\")\n",
    "    albums_df.printSchema()\n",
    "\n",
    "    # Flatten the nested track items within each album\n",
    "    albums_flattened_df = albums_df.select(\n",
    "        F.col(\"name\").alias(\"album_name\"),\n",
    "        F.col(\"release_date\"),\n",
    "        F.col(\"album_type\").alias(\"type\"),\n",
    "        F.element_at(F.col(\"artists.name\"), 1).alias(\"artist_name\"),\n",
    "        F.explode(F.col(\"tracks.items\")).alias(\"track_item\"),\n",
    "        F.col(\"popularity\")\n",
    "    ).select(\n",
    "        F.col(\"album_name\"),\n",
    "        F.col(\"release_date\"),\n",
    "        F.col(\"type\"),\n",
    "        F.col(\"artist_name\"),\n",
    "        F.col(\"track_item.id\").alias(\"track_id\"),\n",
    "        F.col(\"track_item.duration_ms\").alias(\"duration_ms\"),\n",
    "        F.col(\"track_item.track_number\").alias(\"track_number\"),\n",
    "        F.col(\"popularity\")\n",
    "    ).dropDuplicates([\"track_id\"])\n",
    "\n",
    "    print(\"Flattened Albums DataFrame created. Inferred Schema:\")\n",
    "    albums_flattened_df.printSchema()\n",
    "    return albums_flattened_df\n",
    "\n",
    "def get_albums_from_playlist(playlist_id: str):\n",
    "    \"\"\"\n",
    "    Based on the playlist ID, retrieves a list of all album IDs,\n",
    "    and then returns all the tracks from those albums.\n",
    "    \"\"\"\n",
    "    playlist_tracks_df = get_playlists(playlist_id)\n",
    "    if playlist_tracks_df.isEmpty():\n",
    "        empty_album_track_schema = StructType([\n",
    "            StructField(\"album_name\", StringType(), True),\n",
    "            StructField(\"release_date\", StringType(), True),\n",
    "            StructField(\"type\", StringType(), True),\n",
    "            StructField(\"artist_name\", StringType(), True),\n",
    "            StructField(\"track_id\", StringType(), True),\n",
    "            StructField(\"popularity\", LongType(), True),\n",
    "        ])\n",
    "        return spark.createDataFrame([], empty_album_track_schema)\n",
    "    \n",
    "    display(playlist_tracks_df)\n",
    "\n",
    "    album_ids = [row.album_id for row in playlist_tracks_df.select(\"album_id\").distinct().collect()]\n",
    "    album_ids = [aid for aid in album_ids if aid is not None] \n",
    "\n",
    "    if not album_ids:\n",
    "        print(\"No unique album IDs found in the playlist.\")\n",
    "        return spark.createDataFrame([], empty_album_track_schema)\n",
    "\n",
    "    print(f\"Found {len(album_ids)} unique album IDs. Fetching album tracks...\")\n",
    "    albums_df = get_albums(album_ids)\n",
    "    \n",
    "    return albums_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9939ecea-59b2-4160-b435-cf11b321ba00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_tracks(track_lists: list):\n",
    "    if not track_lists:\n",
    "        return spark.createDataFrame([], StructType([StructField(\"id\", StringType(), True), StructField(\"name\", StringType(), True)]))\n",
    "\n",
    "    print(f\"Fetching details for {len(track_lists)} unique tracks...\")\n",
    "    raw_tracks_data = get_batch_items(sp, sp.tracks, track_lists)\n",
    "\n",
    "    if not raw_tracks_data:\n",
    "        print(\"No track details fetched.\")\n",
    "        return spark.createDataFrame([], StructType([StructField(\"id\", StringType(), True), StructField(\"name\", StringType(), True)]))\n",
    "\n",
    "    track_schema=StructType([\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"popularity\", StringType(), True),\n",
    "        StructField(\"duration_ms\", StringType(), True),\n",
    "        StructField(\"explicit\", StringType(), True),\n",
    "        StructField(\"track_number\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "\n",
    "    df_tracks = spark.createDataFrame(raw_tracks_data,track_schema)\n",
    "    print(\"Detailed Tracks DataFrame created. Inferred Schema:\")\n",
    "    df_tracks.printSchema()\n",
    "    return df_tracks\n",
    "\n",
    "\n",
    "def get_tracks_list(playlist_id: str):\n",
    "    \"\"\"\n",
    "    Retrieves a Python list of unique track IDs from albums associated with a playlist.\n",
    "    \"\"\"\n",
    "    \n",
    "    albums_from_playlist_df = get_albums_from_playlist(playlist_id)\n",
    "\n",
    "    if albums_from_playlist_df.isEmpty():\n",
    "        return [] \n",
    "    \n",
    "    tracks_list = [row.track_id for row in albums_from_playlist_df.select(\"track_id\").distinct().collect()]\n",
    "\n",
    "    tracks_list = [tid for tid in tracks_list if tid is not None]\n",
    "    \n",
    "    return tracks_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8005960-d952-495e-b31e-130c87414a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_playlist_album_tracks_details(playlist_id: str):\n",
    "    \"\"\"\n",
    "    Combines album-level track information with detailed track-level information\n",
    "    for all tracks from albums associated with a given playlist.\n",
    "    \"\"\"\n",
    "    albums_df = get_albums_from_playlist(playlist_id)\n",
    "\n",
    "    empty_schema = StructType([ \n",
    "        StructField(\"album_name\", StringType(), True),\n",
    "        StructField(\"release_date\", StringType(), True),\n",
    "        StructField(\"artist_name\", StringType(), True),\n",
    "        StructField(\"artist_id\", StringType(), True),\n",
    "        StructField(\"track_id\", StringType(), True),\n",
    "        StructField(\"track_name\", StringType(), True),\n",
    "        StructField(\"duration_seconds\", DoubleType(), True),\n",
    "        StructField(\"popularity\", LongType(), True),\n",
    "        StructField(\"track_number\", LongType(), True),\n",
    "        StructField(\"Explicit\", BooleanType(), True), \n",
    "        StructField(\"ArtistGenres\", ArrayType(StringType()), True), \n",
    "        StructField(\"ArtistPopularity\", IntegerType(), True), \n",
    "        StructField(\"ArtistFollowers\", LongType(), True), \n",
    "        StructField(\"AlbumType\", StringType(), True), \n",
    "        StructField(\"AlbumPopularity\", IntegerType(), True), \n",
    "        StructField(\"ReleaseYear\", IntegerType(), True), \n",
    "        StructField(\"ReleaseMonth\", IntegerType(), True), \n",
    "        StructField(\"ReleaseDayOfWeek\", IntegerType(), True), \n",
    "        StructField(\"ReleaseDecade\", IntegerType(), True)\n",
    "        ])\n",
    "\n",
    "    if albums_df.isEmpty():\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "\n",
    "    print(\"\\n--- Schema of final_combined_df before final select ---\")\n",
    "    albums_df.printSchema()\n",
    "    print(\"\\n--- Sample data from final_combined_df (first 5 rows) ---\")\n",
    "    albums_df.show(5, truncate=False)\n",
    "\n",
    "    tracks_list = get_tracks_list(playlist_id) \n",
    "\n",
    "    if not tracks_list: \n",
    "        print(\"No track IDs found for detailed track fetching.\")\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "\n",
    "    tracks_details_df = get_tracks(tracks_list)\n",
    "    if tracks_details_df.isEmpty(): \n",
    "        print(\"No detailed track information fetched.\")\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "    \n",
    "    print(\"\\n--- Schema of tracks_details_df ---\")\n",
    "    tracks_details_df.printSchema()\n",
    "\n",
    "    base_tracks_from_playlist = process_playlists(playlist_id) \n",
    "\n",
    "    artist_details_df = get_artist_details_for_enrichment(base_tracks_from_playlist)\n",
    "    album_details_df = albums_df.select(\n",
    "        F.col(\"track_id\"), \n",
    "        F.col(\"type\").alias(\"AlbumType\"),\n",
    "        F.col(\"popularity\").alias(\"AlbumPopularity\")\n",
    "    ).distinct() \n",
    "\n",
    "    print(\"\\n--- Schema of artist_details_df ---\")\n",
    "    artist_details_df.printSchema()\n",
    "\n",
    "    print(\"\\n--- Schema of album_details_df ---\")\n",
    "    album_details_df.printSchema()\n",
    "    \n",
    "    tracks_details_df_renamed = tracks_details_df.select(\n",
    "        F.col(\"id\").alias(\"track_id_from_details\"), \n",
    "        F.col(\"name\").alias(\"track_name_from_details\"),\n",
    "        F.col(\"popularity\").alias(\"track_popularity_from_details\"), \n",
    "        F.col(\"explicit\").alias(\"explicit_from_details\"),\n",
    "        F.col(\"duration_ms\").alias(\"duration_ms_from_details\"),\n",
    "        F.col(\"track_number\").alias(\"track_number_from_details\")\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- DEBUG: Schema of tracks_details_df_renamed before join ---\")\n",
    "    tracks_details_df_renamed.printSchema()\n",
    "    tracks_details_df_renamed.show(5, truncate=False)\n",
    "\n",
    "    albums_tracks_joined = albums_df.join(\n",
    "        tracks_details_df_renamed,\n",
    "        (albums_df[\"track_id\"] == tracks_details_df_renamed[\"track_id_from_details\"]),\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    \n",
    "    final_combined_df = albums_tracks_joined.join(\n",
    "        base_tracks_from_playlist.select(\n",
    "            F.col(\"track.id\").alias(\"original_track_id\"),\n",
    "            F.explode(\"track.artists\").alias(\"artist_exploded\"), \n",
    "            F.col(\"track.explicit\").alias(\"Explicit_Flag\") \n",
    "        ),\n",
    "        (albums_tracks_joined[\"track_id\"] == F.col(\"original_track_id\")),\n",
    "        how='left'\n",
    "    ).drop(\"original_track_id\")\n",
    "     \n",
    "    final_combined_df = final_combined_df.join(\n",
    "        artist_details_df,\n",
    "        (final_combined_df[\"artist_exploded.id\"] == artist_details_df[\"artist_id\"]),\n",
    "        how='left'\n",
    "    ).drop(\"artist_exploded.id\")\n",
    "    \n",
    "    print(\"\\n--- Schema of final_combined_df before final select ---\")\n",
    "    final_combined_df.printSchema()\n",
    "    print(\"\\n--- Sample data from final_combined_df (first 5 rows) ---\")\n",
    "    final_combined_df.show(5, truncate=False)\n",
    "    \n",
    "    \n",
    "\n",
    "    albums_tracks_joined_final = (\n",
    "        final_combined_df\n",
    "        .select(\n",
    "            F.col(\"album_name\").alias(\"AlbumName\"),\n",
    "            F.col(\"release_date\").cast(DateType()).alias(\"ReleaseDate\"),\n",
    "            F.col(\"artist_exploded.name\").alias(\"ArtistName\"), \n",
    "            F.col(\"artist_exploded.id\").alias(\"ArtistId\"),\n",
    "            F.col(\"track_id\").alias(\"TrackId\"),\n",
    "            F.col(\"track_name_from_details\").alias(\"TrackName\"), \n",
    "            (F.col(\"duration_ms\") / 1000).alias('DurationSeconds'),\n",
    "            F.from_unixtime(F.col(\"duration_ms\") / 1000, 'mm:ss').alias('Duration'), \n",
    "            final_combined_df[\"popularity\"].alias(\"Popularity\"), \n",
    "            F.col(\"track_number\"),\n",
    "            F.col(\"Explicit_Flag\").alias(\"Explicit\"), \n",
    "            F.col(\"ArtistGenres\"),\n",
    "            F.col(\"ArtistPopularity\"),\n",
    "            F.col(\"ArtistFollowers\"),\n",
    "            F.col(\"type\").alias(\"AlbumType\"), \n",
    "            albums_df[\"popularity\"].alias(\"AlbumPopularity\"), \n",
    "            F.year(F.col(\"release_date\")).alias(\"ReleaseYear\"),\n",
    "            F.month(F.col(\"release_date\")).alias(\"ReleaseMonth\"),\n",
    "            F.dayofweek(F.col(\"release_date\")).alias(\"ReleaseDayOfWeek\"),\n",
    "            (F.floor(F.year(F.col(\"release_date\")) / 10) * 10).alias(\"ReleaseDecade\")\n",
    "        )\n",
    "    )\n",
    "    print(\"Combined Albums and Tracks DataFrame created. Inferred Schema:\")\n",
    "    albums_tracks_joined_final.printSchema()\n",
    "    return albums_tracks_joined_final\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbbd72b4-74e9-46bc-8198-9c5c3f79a1d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5540c1b3-c057-4445-ba4a-fa36fd1c0e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS spotify;\n",
    "\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS spotify.\n",
    "full_albums_enriched (\n",
    "  AlbumName STRING,\n",
    "  ReleaseDate DATE,\n",
    "  ArtistName STRING,\n",
    "  ArtistId STRING,          \n",
    "  TrackId STRING,\n",
    "  TrackName STRING,\n",
    "  DurationSeconds DECIMAL(8, 2),\n",
    "  Duration STRING,\n",
    "  Popularity INT,          \n",
    "  TrackNumber INT,\n",
    "  Explicit BOOLEAN,         \n",
    "  ArtistGenres ARRAY<STRING>,\n",
    "  ArtistPopularity INT,    \n",
    "  ArtistFollowers BIGINT,   \n",
    "  AlbumType STRING,         \n",
    "  AlbumPopularity INT,      \n",
    "  ReleaseYear INT,\n",
    "  ReleaseMonth INT,\n",
    "  ReleaseDayOfWeek INT,\n",
    "  ReleaseDecade INT\n",
    ") PARTITIONED BY (ArtistName);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a2cb14a-c19f-4520-829d-867e78744925",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_albums_from_playlist_enriched = get_playlist_album_tracks_details(playlistid)\n",
    "\n",
    "full_albums_from_playlist_enriched.createOrReplaceTempView(\"full_album_enriched_temp_view\") \n",
    "\n",
    "full_albums_from_playlist_enriched.write.mode(\"overwrite\").insertInto(\"spotify.full_albums_enriched\")\n",
    "print(\"Data loaded into spotify.full_albums_enriched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a71f49fa-5ec5-4bda-bae1-55a80cdc9272",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_5_longest_albums = spark.sql(\"\"\"\n",
    "               SELECT\n",
    "                    AlbumName,\n",
    "                    SUM(DurationSeconds) AS AlbumDuration\n",
    "                FROM\n",
    "                    spotify.full_albums_enriched \n",
    "                GROUP BY\n",
    "                    AlbumName\n",
    "                ORDER BY AlbumDuration DESC\n",
    "                LIMIT 5\n",
    "                \"\"\")\n",
    "\n",
    "albums_with_most_popular_songs = spark.sql(\"\"\"\n",
    "                                           SELECT\n",
    "                                                AlbumName,\n",
    "                                                CASE\n",
    "                                                    WHEN\n",
    "                                                        Popularity BETWEEN 0 AND 40 THEN 'NotPopular'\n",
    "                                                    WHEN\n",
    "                                                        Popularity BETWEEN 41 AND 100 THEN 'Popular'\n",
    "                                                    ELSE NULL\n",
    "                                                END AS PopularityCategory \n",
    "                                            FROM\n",
    "                                                spotify.full_albums_enriched \n",
    "                                           \"\"\")\n",
    "\n",
    "albums_per_popularity = (albums_with_most_popular_songs\n",
    "    .groupBy(\"AlbumName\")\n",
    "    .pivot(\"PopularityCategory\")\n",
    "    .agg(F.count(\"PopularityCategory\"))\n",
    "    .na.fill(0)\n",
    ")\n",
    "\n",
    "\n",
    "albums_by_artist_popularity = spark.sql(\"\"\"\n",
    "                            SELECT\n",
    "                                AlbumName,\n",
    "                                CASE\n",
    "                                    WHEN ArtistPopularity BETWEEN 0 AND 40 THEN 'LessPopularArtists'\n",
    "                                    WHEN ArtistPopularity BETWEEN 41 AND 70 THEN 'MediumPopularArtists'\n",
    "                                    WHEN ArtistPopularity BETWEEN 71 AND 100 THEN 'HighlyPopularArtists'\n",
    "                                    ELSE 'Unknown'\n",
    "                                END AS ArtistPopularityCategory\n",
    "                            FROM\n",
    "                                spotify.full_albums_enriched \n",
    "                            \"\"\")\n",
    "\n",
    "albums_per_artist_popularity = (albums_by_artist_popularity\n",
    "    .groupBy(\"AlbumName\")\n",
    "    .pivot(\"ArtistPopularityCategory\")\n",
    "    .agg(F.count(\"ArtistPopularityCategory\"))\n",
    "    .na.fill(0)\n",
    ")\n",
    "\n",
    "\n",
    "tracks_per_genre = spark.sql(\"\"\"\n",
    "                               SELECT\n",
    "                                    genre_exploded AS Genre,\n",
    "                                    COUNT(TrackId) AS NoOfTracksInGenre\n",
    "                               FROM\n",
    "                                    spotify.full_albums_enriched\n",
    "                               LATERAL VIEW EXPLODE(ArtistGenres) exploded_genres AS genre_exploded -- Use new ArtistGenres\n",
    "                               WHERE genre_exploded IS NOT NULL\n",
    "                               GROUP BY\n",
    "                                    genre_exploded\n",
    "                               ORDER BY NoOfTracksInGenre DESC\n",
    "                              \"\"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb3a79c-1ac4-43de-9e2c-00a508ddd092",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_5_longest_albums.write.option(\"header\", \"true\").mode('overwrite').saveAsTable('spotify.top_5_longest_albums')\n",
    "albums_per_popularity.write.option(\"header\", \"true\").mode('overwrite').saveAsTable('spotify.albums_per_popularity')\n",
    "\n",
    "albums_per_artist_popularity.write.option(\"header\", \"true\").mode('overwrite').saveAsTable('spotify.albums_per_artist_popularity')\n",
    "\n",
    "tracks_per_genre.write.option(\"header\", \"true\").mode('overwrite').saveAsTable('spotify.tracks_per_genre')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5817289358515668,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Spotify_ETL",
   "widgets": {
    "playlist_id": {
     "currentValue": "3cEYpjA9oz9GiPac4AsH4n",
     "nuid": "b765b593-171e-4b5e-b5f9-72ba6fda1925",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "playlist_id",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "playlist_id",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
